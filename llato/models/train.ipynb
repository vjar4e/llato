{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree \n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "CSV_PATH = \"../data/csv/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for filename in os.listdir(CSV_PATH):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        dfs[filename[:-4]] = pd.read_csv(CSV_PATH + filename)\n",
    "        if DEBUG:\n",
    "            dfs[filename[:-4]] = dfs[filename[:-4]].sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"case_classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tokenize(s: str) -> [str]: \n",
    "    return [ord(i) for i in list(s.lower())]\n",
    "\n",
    "def decode(l: [str]) -> str:\n",
    "    return ''.join([chr(i) for i in l])\n",
    "\n",
    "\n",
    "def pad(s: [int], max_len: int) -> [int]:\n",
    "    return np.pad(s, (0, max_len - len(s)), 'constant', constant_values=(0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXISTS = os.path.isfile(f'{MODEL_NAME}.skops')\n",
    "\n",
    "if not EXISTS:\n",
    "    dfs_w_cases = (\n",
    "        dfs['adjectives'],\n",
    "        dfs['halfparticiples'],\n",
    "        dfs['nouns'],\n",
    "        dfs['numerals'],\n",
    "        dfs['pronoun'],\n",
    "        dfs['subparticles'],\n",
    "    )\n",
    "\n",
    "    CASES = ['V.', 'K.', 'N.', 'G.', 'Ä®n.', 'Vt.']\n",
    "\n",
    "    case_df = pd.concat(dfs_w_cases, ignore_index=True)\n",
    "    case_df = case_df[[\"word\", \"case\"]]\n",
    "    case_df = case_df.dropna()\n",
    "    case_df = case_df.drop_duplicates(subset=['word'])\n",
    "\n",
    "    X = case_df['word']\n",
    "    y = case_df['case']\n",
    "\n",
    "    # pad each x\n",
    "\n",
    "    X = X.apply(tokenize)\n",
    "    global max_len\n",
    "    max_len = max(X.apply(len))\n",
    "    X = X.apply(lambda x: pad(x, max_len))\n",
    "    y = y.apply(lambda x: CASES.index(x))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skops.io import dump, load\n",
    "\n",
    "\n",
    "# Load case_classifier.skops if exists or train a new one\n",
    "if EXISTS:\n",
    "    case_classifier = load(f'{MODEL_NAME}.skops')\n",
    "else:\n",
    "    case_classifier = RandomForestClassifier()\n",
    "    case_classifier.fit(X_train.tolist(), y_train.tolist())\n",
    "    case_classifier.score(X_test.tolist(), y_test.tolist())\n",
    "    dump(case_classifier, f'{MODEL_NAME}.skops')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b383554375843feb898ba118ec847cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='', description='word'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, HTML\n",
    "\n",
    "\n",
    "@interact\n",
    "def predict_case(word: str = \"\") -> HTML:\n",
    "    res = pd.DataFrame(columns=['case', 'probability'])\n",
    "    for i, v in enumerate(case_classifier.predict_proba([pad(tokenize(word), max_len)])[0].tolist()):\n",
    "        res.loc[i] = [CASES[i], v]\n",
    "    return HTML(res.set_index(\"case\").transpose().sort_values(by='probability', axis=1, ascending=False).to_html(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
